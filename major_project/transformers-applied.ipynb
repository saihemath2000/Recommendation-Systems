{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93fba32f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-02T18:48:47.847773Z",
     "iopub.status.busy": "2024-05-02T18:48:47.847197Z",
     "iopub.status.idle": "2024-05-02T18:48:48.621606Z",
     "shell.execute_reply": "2024-05-02T18:48:48.620705Z"
    },
    "papermill": {
     "duration": 0.79052,
     "end_time": "2024-05-02T18:48:48.623773",
     "exception": false,
     "start_time": "2024-05-02T18:48:47.833253",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/santandar-processed-data/fdata.csv\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "22d35ae6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-02T18:48:48.650111Z",
     "iopub.status.busy": "2024-05-02T18:48:48.649516Z",
     "iopub.status.idle": "2024-05-02T18:50:02.276440Z",
     "shell.execute_reply": "2024-05-02T18:50:02.275560Z"
    },
    "papermill": {
     "duration": 73.642636,
     "end_time": "2024-05-02T18:50:02.279045",
     "exception": false,
     "start_time": "2024-05-02T18:48:48.636409",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"/kaggle/input/santandar-processed-data/fdata.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a912907a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-02T18:50:02.306867Z",
     "iopub.status.busy": "2024-05-02T18:50:02.306058Z",
     "iopub.status.idle": "2024-05-02T18:50:04.116735Z",
     "shell.execute_reply": "2024-05-02T18:50:04.115790Z"
    },
    "papermill": {
     "duration": 1.826687,
     "end_time": "2024-05-02T18:50:04.119174",
     "exception": false,
     "start_time": "2024-05-02T18:50:02.292487",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "cols_to_remove = ['employee_index', 'country_residence', 'new_customer_index', 'primary_customer', \n",
    "                  'customer_type_beginning_month', 'customer_relation_type_beginning_month', \n",
    "                  'residence_index', 'foreigner_index','registration_date']\n",
    "\n",
    "train = train.drop(cols_to_remove, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0f233fa3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-02T18:50:04.146779Z",
     "iopub.status.busy": "2024-05-02T18:50:04.146082Z",
     "iopub.status.idle": "2024-05-02T18:50:18.439655Z",
     "shell.execute_reply": "2024-05-02T18:50:18.438852Z"
    },
    "papermill": {
     "duration": 14.310208,
     "end_time": "2024-05-02T18:50:18.442104",
     "exception": false,
     "start_time": "2024-05-02T18:50:04.131896",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# 1. Convert date columns to seconds\n",
    "train['fecha_alta']=train['data_date']\n",
    "train['data_date'] = pd.to_datetime(train['data_date']).astype(int) / 10**9\n",
    "\n",
    "\n",
    "# 2. Encode object columns to integer values using label encoder\n",
    "encoder = LabelEncoder()\n",
    "train['channel_used'] = encoder.fit_transform(train['channel_used'])\n",
    "train['province_name'] = encoder.fit_transform(train['province_name'])\n",
    "train['segmentation'] = encoder.fit_transform(train['segmentation'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c9054181",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-02T18:50:18.467840Z",
     "iopub.status.busy": "2024-05-02T18:50:18.467549Z",
     "iopub.status.idle": "2024-05-02T18:50:18.485992Z",
     "shell.execute_reply": "2024-05-02T18:50:18.485176Z"
    },
    "papermill": {
     "duration": 0.033679,
     "end_time": "2024-05-02T18:50:18.488263",
     "exception": false,
     "start_time": "2024-05-02T18:50:18.454584",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 13618663 entries, 0 to 13618662\n",
      "Data columns (total 35 columns):\n",
      " #   Column                        Dtype  \n",
      "---  ------                        -----  \n",
      " 0   data_date                     float64\n",
      " 1   gender                        int64  \n",
      " 2   seniority                     float64\n",
      " 3   channel_used                  int64  \n",
      " 4   province_code                 float64\n",
      " 5   province_name                 int64  \n",
      " 6   activity_index                float64\n",
      " 7   gross_income_household        float64\n",
      " 8   segmentation                  int64  \n",
      " 9   prod_savings_account          int64  \n",
      " 10  prod_guarantees               int64  \n",
      " 11  prod_current_accounts         int64  \n",
      " 12  prod_derivative_account       int64  \n",
      " 13  prod_payroll_account          int64  \n",
      " 14  prod_junior_account           int64  \n",
      " 15  prod_mas_particular_account   int64  \n",
      " 16  prod_particular_account       int64  \n",
      " 17  prod_particular_plus_account  int64  \n",
      " 18  prod_short_term_deposits      int64  \n",
      " 19  prod_medium_term_deposits     int64  \n",
      " 20  prod_long_term_deposits       int64  \n",
      " 21  prod_e_account                int64  \n",
      " 22  prod_funds                    int64  \n",
      " 23  prod_mortgage                 int64  \n",
      " 24  prod_pensions1                int64  \n",
      " 25  prod_loans                    int64  \n",
      " 26  prod_taxes                    int64  \n",
      " 27  prod_credit_card              int64  \n",
      " 28  prod_securities               int64  \n",
      " 29  prod_home_account             int64  \n",
      " 30  prod_payroll                  float64\n",
      " 31  prod_pensions2                float64\n",
      " 32  prod_direct_debit             int64  \n",
      " 33  age_group                     int64  \n",
      " 34  fecha_alta                    object \n",
      "dtypes: float64(7), int64(27), object(1)\n",
      "memory usage: 3.6+ GB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2bb65bc1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-02T18:50:18.514275Z",
     "iopub.status.busy": "2024-05-02T18:50:18.513607Z",
     "iopub.status.idle": "2024-05-02T18:50:18.541313Z",
     "shell.execute_reply": "2024-05-02T18:50:18.540414Z"
    },
    "papermill": {
     "duration": 0.042911,
     "end_time": "2024-05-02T18:50:18.543384",
     "exception": false,
     "start_time": "2024-05-02T18:50:18.500473",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data_date</th>\n",
       "      <th>gender</th>\n",
       "      <th>seniority</th>\n",
       "      <th>channel_used</th>\n",
       "      <th>province_code</th>\n",
       "      <th>province_name</th>\n",
       "      <th>activity_index</th>\n",
       "      <th>gross_income_household</th>\n",
       "      <th>segmentation</th>\n",
       "      <th>prod_savings_account</th>\n",
       "      <th>...</th>\n",
       "      <th>prod_loans</th>\n",
       "      <th>prod_taxes</th>\n",
       "      <th>prod_credit_card</th>\n",
       "      <th>prod_securities</th>\n",
       "      <th>prod_home_account</th>\n",
       "      <th>prod_payroll</th>\n",
       "      <th>prod_pensions2</th>\n",
       "      <th>prod_direct_debit</th>\n",
       "      <th>age_group</th>\n",
       "      <th>fecha_alta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.422403e+09</td>\n",
       "      <td>0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>153</td>\n",
       "      <td>29.0</td>\n",
       "      <td>31</td>\n",
       "      <td>1.0</td>\n",
       "      <td>87218.10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2015-01-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.422403e+09</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>150</td>\n",
       "      <td>13.0</td>\n",
       "      <td>16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35548.74</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2015-01-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.422403e+09</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>150</td>\n",
       "      <td>13.0</td>\n",
       "      <td>16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>122179.11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2015-01-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.422403e+09</td>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>149</td>\n",
       "      <td>50.0</td>\n",
       "      <td>51</td>\n",
       "      <td>0.0</td>\n",
       "      <td>119775.54</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2015-01-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.422403e+09</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>150</td>\n",
       "      <td>50.0</td>\n",
       "      <td>51</td>\n",
       "      <td>1.0</td>\n",
       "      <td>101850.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2015-01-28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      data_date  gender  seniority  channel_used  province_code  \\\n",
       "0  1.422403e+09       0        6.0           153           29.0   \n",
       "1  1.422403e+09       1       35.0           150           13.0   \n",
       "2  1.422403e+09       1       35.0           150           13.0   \n",
       "3  1.422403e+09       0       35.0           149           50.0   \n",
       "4  1.422403e+09       1       35.0           150           50.0   \n",
       "\n",
       "   province_name  activity_index  gross_income_household  segmentation  \\\n",
       "0             31             1.0                87218.10             1   \n",
       "1             16             0.0                35548.74             0   \n",
       "2             16             0.0               122179.11             0   \n",
       "3             51             0.0               119775.54             0   \n",
       "4             51             1.0               101850.00             0   \n",
       "\n",
       "   prod_savings_account  ...  prod_loans  prod_taxes  prod_credit_card  \\\n",
       "0                     0  ...           0           0                 0   \n",
       "1                     0  ...           0           0                 0   \n",
       "2                     0  ...           0           0                 0   \n",
       "3                     0  ...           0           0                 0   \n",
       "4                     0  ...           0           0                 0   \n",
       "\n",
       "   prod_securities  prod_home_account  prod_payroll  prod_pensions2  \\\n",
       "0                0                  0           0.0             0.0   \n",
       "1                0                  0           0.0             0.0   \n",
       "2                0                  0           0.0             0.0   \n",
       "3                0                  0           0.0             0.0   \n",
       "4                0                  0           0.0             0.0   \n",
       "\n",
       "   prod_direct_debit  age_group  fecha_alta  \n",
       "0                  0          1  2015-01-28  \n",
       "1                  0          1  2015-01-28  \n",
       "2                  0          1  2015-01-28  \n",
       "3                  0          1  2015-01-28  \n",
       "4                  0          1  2015-01-28  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "04b256b0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-02T18:50:18.569488Z",
     "iopub.status.busy": "2024-05-02T18:50:18.569219Z",
     "iopub.status.idle": "2024-05-02T18:50:18.576306Z",
     "shell.execute_reply": "2024-05-02T18:50:18.575511Z"
    },
    "papermill": {
     "duration": 0.022161,
     "end_time": "2024-05-02T18:50:18.578133",
     "exception": false,
     "start_time": "2024-05-02T18:50:18.555972",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "data_date                       1422403200.0\n",
       "gender                                     0\n",
       "seniority                                6.0\n",
       "channel_used                             153\n",
       "province_code                           29.0\n",
       "province_name                             31\n",
       "activity_index                           1.0\n",
       "gross_income_household               87218.1\n",
       "segmentation                               1\n",
       "prod_savings_account                       0\n",
       "prod_guarantees                            0\n",
       "prod_current_accounts                      1\n",
       "prod_derivative_account                    0\n",
       "prod_payroll_account                       0\n",
       "prod_junior_account                        0\n",
       "prod_mas_particular_account                0\n",
       "prod_particular_account                    0\n",
       "prod_particular_plus_account               0\n",
       "prod_short_term_deposits                   0\n",
       "prod_medium_term_deposits                  0\n",
       "prod_long_term_deposits                    0\n",
       "prod_e_account                             0\n",
       "prod_funds                                 0\n",
       "prod_mortgage                              0\n",
       "prod_pensions1                             0\n",
       "prod_loans                                 0\n",
       "prod_taxes                                 0\n",
       "prod_credit_card                           0\n",
       "prod_securities                            0\n",
       "prod_home_account                          0\n",
       "prod_payroll                             0.0\n",
       "prod_pensions2                           0.0\n",
       "prod_direct_debit                          0\n",
       "age_group                                  1\n",
       "fecha_alta                        2015-01-28\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "201c540d",
   "metadata": {
    "papermill": {
     "duration": 0.012507,
     "end_time": "2024-05-02T18:50:18.603560",
     "exception": false,
     "start_time": "2024-05-02T18:50:18.591053",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Popular Recommendation System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aa5d2151",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-02T18:50:18.630209Z",
     "iopub.status.busy": "2024-05-02T18:50:18.629949Z",
     "iopub.status.idle": "2024-05-02T18:50:20.203504Z",
     "shell.execute_reply": "2024-05-02T18:50:20.202588Z"
    },
    "papermill": {
     "duration": 1.589656,
     "end_time": "2024-05-02T18:50:20.205853",
     "exception": false,
     "start_time": "2024-05-02T18:50:18.616197",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_24/474524568.py:13: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  popular_df = pd.concat([popular_df, pd.DataFrame(data_to_concat)], ignore_index=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product</th>\n",
       "      <th>sales_volume</th>\n",
       "      <th>sales_frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>prod_direct_debit</td>\n",
       "      <td>1744771</td>\n",
       "      <td>0.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>prod_e_account</td>\n",
       "      <td>1128003</td>\n",
       "      <td>0.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>prod_pensions2</td>\n",
       "      <td>809832</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>prod_payroll</td>\n",
       "      <td>745728</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>prod_taxes</td>\n",
       "      <td>706788</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>prod_long_term_deposits</td>\n",
       "      <td>586204</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>prod_credit_card</td>\n",
       "      <td>605550</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>prod_securities</td>\n",
       "      <td>349306</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>prod_funds</td>\n",
       "      <td>252155</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>prod_pensions1</td>\n",
       "      <td>125077</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>prod_mortgage</td>\n",
       "      <td>80106</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>prod_short_term_deposits</td>\n",
       "      <td>23817</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>prod_medium_term_deposits</td>\n",
       "      <td>22663</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>prod_loans</td>\n",
       "      <td>34523</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>prod_home_account</td>\n",
       "      <td>52484</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      product sales_volume  sales_frequency\n",
       "14          prod_direct_debit      1744771             0.13\n",
       "3              prod_e_account      1128003             0.08\n",
       "13             prod_pensions2       809832             0.06\n",
       "12               prod_payroll       745728             0.05\n",
       "8                  prod_taxes       706788             0.05\n",
       "2     prod_long_term_deposits       586204             0.04\n",
       "9            prod_credit_card       605550             0.04\n",
       "10            prod_securities       349306             0.03\n",
       "4                  prod_funds       252155             0.02\n",
       "6              prod_pensions1       125077             0.01\n",
       "5               prod_mortgage        80106             0.01\n",
       "0    prod_short_term_deposits        23817             0.00\n",
       "1   prod_medium_term_deposits        22663             0.00\n",
       "7                  prod_loans        34523             0.00\n",
       "11          prod_home_account        52484             0.00"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define the popularity metric: Purchasing Amount as the single metric\n",
    "popular_df = pd.DataFrame(columns=['product', 'sales_volume', 'sales_frequency'])\n",
    "\n",
    "data_to_concat = []\n",
    "\n",
    "for i in train.columns[18:-2]:\n",
    "    sales_volume = train[i].value_counts().get(1, 0)  # Get sales volume, handle case where value 1 is not present\n",
    "    sales_frequency = round(sales_volume / train.shape[0], 2)  # Calculate sales frequency\n",
    "    data_to_concat.append({'product': i, 'sales_volume': sales_volume, 'sales_frequency': sales_frequency})\n",
    "\n",
    "popular_df = pd.concat([popular_df, pd.DataFrame(data_to_concat)], ignore_index=True)\n",
    "\n",
    "popular_df.sort_values('sales_frequency', inplace=True, ascending=False)\n",
    "popular_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b1e0929",
   "metadata": {
    "papermill": {
     "duration": 0.013062,
     "end_time": "2024-05-02T18:50:20.232817",
     "exception": false,
     "start_time": "2024-05-02T18:50:20.219755",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Enhanced Popularity-based Product Recommender with Time Decay Adjustment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "22ba4877",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-02T18:50:20.259922Z",
     "iopub.status.busy": "2024-05-02T18:50:20.259617Z",
     "iopub.status.idle": "2024-05-02T18:50:20.971082Z",
     "shell.execute_reply": "2024-05-02T18:50:20.969793Z"
    },
    "papermill": {
     "duration": 0.727192,
     "end_time": "2024-05-02T18:50:20.972980",
     "exception": true,
     "start_time": "2024-05-02T18:50:20.245788",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "positional indexers are out-of-bounds",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Try adding Time Decay impact on the Popularity-based Recommendation:\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmath\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m exp\n\u001b[0;32m----> 4\u001b[0m popular_df_time \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m22\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m23\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m24\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m25\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m26\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m27\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m28\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m29\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m31\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m33\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m34\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m35\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m36\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m37\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m38\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m39\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m40\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m41\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m42\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m43\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m44\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m45\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m      5\u001b[0m popular_df_time[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124myear\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m popular_df_time[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfecha_dato\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mdt\u001b[38;5;241m.\u001b[39myear\n\u001b[1;32m      6\u001b[0m popular_df_time[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmonth\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m popular_df_time[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfecha_dato\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mdt\u001b[38;5;241m.\u001b[39mmonth\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/indexing.py:1184\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1182\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_scalar_access(key):\n\u001b[1;32m   1183\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_get_value(\u001b[38;5;241m*\u001b[39mkey, takeable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_takeable)\n\u001b[0;32m-> 1184\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_tuple\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1185\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1186\u001b[0m     \u001b[38;5;66;03m# we by definition only have the 0th axis\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m     axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxis \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/indexing.py:1690\u001b[0m, in \u001b[0;36m_iLocIndexer._getitem_tuple\u001b[0;34m(self, tup)\u001b[0m\n\u001b[1;32m   1689\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_getitem_tuple\u001b[39m(\u001b[38;5;28mself\u001b[39m, tup: \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m-> 1690\u001b[0m     tup \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_tuple_indexer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtup\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1691\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m suppress(IndexingError):\n\u001b[1;32m   1692\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_lowerdim(tup)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/indexing.py:966\u001b[0m, in \u001b[0;36m_LocationIndexer._validate_tuple_indexer\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    964\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(key):\n\u001b[1;32m    965\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 966\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_key\u001b[49m\u001b[43m(\u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    967\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    968\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    969\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLocation based indexing can only have \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    970\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_valid_types\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] types\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    971\u001b[0m         ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/indexing.py:1612\u001b[0m, in \u001b[0;36m_iLocIndexer._validate_key\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1610\u001b[0m     \u001b[38;5;66;03m# check that the key does not exceed the maximum size of the index\u001b[39;00m\n\u001b[1;32m   1611\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(arr) \u001b[38;5;129;01mand\u001b[39;00m (arr\u001b[38;5;241m.\u001b[39mmax() \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m len_axis \u001b[38;5;129;01mor\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mmin() \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m-\u001b[39mlen_axis):\n\u001b[0;32m-> 1612\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpositional indexers are out-of-bounds\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1613\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1614\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan only index by location with a [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_valid_types\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mIndexError\u001b[0m: positional indexers are out-of-bounds"
     ]
    }
   ],
   "source": [
    "# Try adding Time Decay impact on the Popularity-based Recommendation:\n",
    "from math import exp\n",
    "\n",
    "popular_df_time = train.iloc[:,[0,1,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45]]\n",
    "popular_df_time['year'] = popular_df_time['fecha_dato'].dt.year\n",
    "popular_df_time['month'] = popular_df_time['fecha_dato'].dt.month\n",
    "popular_df_time['day'] = '01'\n",
    "\n",
    "# For computational ease, using the 2016 data ONLY\n",
    "#popular_df_time = popular_df_time[popular_df_time['year'] == 2016]\n",
    "\n",
    "# Group by customer id, year and month \n",
    "popular_df_time['year_month'] = pd.to_datetime(popular_df_time[['year','month','day']])\n",
    "popular_df_time.drop(['cust_id','year','month','day'], axis = 1, inplace = True)\n",
    "popular_df_time_g = popular_df_time.groupby(['year_month'], as_index = False).sum()\n",
    "\n",
    "# Transform the table\n",
    "id_columns = ['year_month']\n",
    "\n",
    "# Reshape the data \n",
    "popular_df_time_g = pd.melt(popular_df_time_g, id_vars=id_columns, var_name='product_name', value_name='sales_volume')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd3e875",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for col in train.columns.tolist():\n",
    "    print(f\"Unique values in {col}: {train[col].unique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c628dc0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-02T13:17:07.370915Z",
     "iopub.status.busy": "2024-05-02T13:17:07.370123Z",
     "iopub.status.idle": "2024-05-02T13:17:10.889465Z",
     "shell.execute_reply": "2024-05-02T13:17:10.888679Z",
     "shell.execute_reply.started": "2024-05-02T13:17:07.370877Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_without_missing = train.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b0c60e4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-02T13:17:21.093681Z",
     "iopub.status.busy": "2024-05-02T13:17:21.092983Z",
     "iopub.status.idle": "2024-05-02T13:17:22.816310Z",
     "shell.execute_reply": "2024-05-02T13:17:22.814970Z",
     "shell.execute_reply.started": "2024-05-02T13:17:21.093651Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_without_missing.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f1bf35a",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "product_list = [\n",
    "    'prod_guarantees',\n",
    "    'prod_current_accounts',\n",
    "    'prod_derivative_account',\n",
    "    'prod_payroll_account',\n",
    "    'prod_junior_account',\n",
    "    'prod_mas_particular_account',\n",
    "    'prod_particular_account',\n",
    "    'prod_particular_plus_account',\n",
    "    'prod_short_term_deposits',\n",
    "    'prod_medium_term_deposits',\n",
    "    'prod_long_term_deposits',\n",
    "    'prod_e_account',\n",
    "    'prod_funds',\n",
    "    'prod_mortgage',\n",
    "    'prod_pensions1',\n",
    "    'prod_loans',\n",
    "    'prod_taxes',\n",
    "    'prod_credit_card',\n",
    "    'prod_securities',\n",
    "    'prod_home_account',\n",
    "    'prod_payroll',\n",
    "    'prod_pensions2',\n",
    "    'prod_direct_debit'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc285d27",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(product_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4957af75",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-02T13:17:26.723720Z",
     "iopub.status.busy": "2024-05-02T13:17:26.723347Z",
     "iopub.status.idle": "2024-05-02T13:17:26.814923Z",
     "shell.execute_reply": "2024-05-02T13:17:26.814058Z",
     "shell.execute_reply.started": "2024-05-02T13:17:26.723691Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f338d8b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-02T13:17:28.879219Z",
     "iopub.status.busy": "2024-05-02T13:17:28.878502Z",
     "iopub.status.idle": "2024-05-02T13:17:40.969147Z",
     "shell.execute_reply": "2024-05-02T13:17:40.968224Z",
     "shell.execute_reply.started": "2024-05-02T13:17:28.879185Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense, Concatenate, Embedding, Flatten, MultiHeadAttention, LayerNormalization\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c559b839",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "# For multiple columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cd3832f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-02T13:17:54.172948Z",
     "iopub.status.busy": "2024-05-02T13:17:54.171691Z",
     "iopub.status.idle": "2024-05-02T13:18:02.961962Z",
     "shell.execute_reply": "2024-05-02T13:18:02.961159Z",
     "shell.execute_reply.started": "2024-05-02T13:17:54.172909Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X = data_without_missing.loc[:, 'data_date':'segmentation']\n",
    "#y = data_without_missing.loc[:, 'prod_guarantees'][:100000] for single col\n",
    "y = data_without_missing.loc[:, 'prod_guarantees':'prod_direct_debit'] \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dd563d9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-02T13:18:10.567891Z",
     "iopub.status.busy": "2024-05-02T13:18:10.567503Z",
     "iopub.status.idle": "2024-05-02T13:18:12.520469Z",
     "shell.execute_reply": "2024-05-02T13:18:12.519335Z",
     "shell.execute_reply.started": "2024-05-02T13:18:10.567860Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Standardize numerical features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "728e6e27",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-02T13:18:15.805365Z",
     "iopub.status.busy": "2024-05-02T13:18:15.804512Z",
     "iopub.status.idle": "2024-05-02T13:18:15.809513Z",
     "shell.execute_reply": "2024-05-02T13:18:15.808562Z",
     "shell.execute_reply.started": "2024-05-02T13:18:15.805330Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "pred = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9a2f610",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-02T13:18:19.974478Z",
     "iopub.status.busy": "2024-05-02T13:18:19.974105Z",
     "iopub.status.idle": "2024-05-02T13:18:20.769545Z",
     "shell.execute_reply": "2024-05-02T13:18:20.768593Z",
     "shell.execute_reply.started": "2024-05-02T13:18:19.974450Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense, Embedding, GlobalAveragePooling1D, Reshape\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import MultiHeadAttention, LayerNormalization, Dropout\n",
    "\n",
    "# # Generate dummy numerical data\n",
    "# X_train = np.random.randint(0, 100, size=(1000, 10))  # 1000 samples, 10 numerical features\n",
    "# y_train = np.random.randint(0, 2, size=(1000,))  # Binary labels (0 or 1)\n",
    "\n",
    "# Define input layer\n",
    "input_layer = Input(shape=(9,), name='input_layer')\n",
    "\n",
    "# Add embedding layer\n",
    "embedding_dim = 64  # Dimension of the embedding space\n",
    "vocab_size = 100  # Vocabulary size\n",
    "embedding_layer = Embedding(input_dim=vocab_size, output_dim=embedding_dim)(input_layer)\n",
    "\n",
    "# Add Reshape layer to fit Transformer's input shape\n",
    "reshaped_embedding = Reshape((-1, embedding_dim))(embedding_layer)\n",
    "\n",
    "# Add Transformer layers\n",
    "num_heads = 2\n",
    "dff = 32\n",
    "num_layers = 2\n",
    "\n",
    "# Multi-Head Attention\n",
    "multi_head_attention = MultiHeadAttention(num_heads=num_heads, key_dim=embedding_dim)(reshaped_embedding, reshaped_embedding)\n",
    "multi_head_attention = Dropout(0.1)(multi_head_attention)\n",
    "multi_head_attention = LayerNormalization()(multi_head_attention + reshaped_embedding)\n",
    "\n",
    "# Feed Forward Network\n",
    "ffn = Dense(dff, activation='relu')(multi_head_attention)\n",
    "ffn = Dense(embedding_dim)(ffn)\n",
    "ffn = Dropout(0.1)(ffn)\n",
    "transformer_output = LayerNormalization()(ffn + multi_head_attention)\n",
    "\n",
    "# Global average pooling\n",
    "pooled_output = GlobalAveragePooling1D()(transformer_output)\n",
    "\n",
    "# Output layer\n",
    "output_layer = Dense(1, activation='sigmoid')(pooled_output)\n",
    "\n",
    "# Define model\n",
    "model = Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "# Compile model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4f48f9e",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import os\n",
    "\n",
    "# # Define the model file name\n",
    "# model_file = 'transformerm.h5'\n",
    "\n",
    "# # Check if the model file already exists\n",
    "# if os.path.exists(model_file):\n",
    "#     # If the file exists, delete it\n",
    "#     os.remove(model_file)\n",
    "\n",
    "# # Save the model\n",
    "# model.save(model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac7c7979",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for col in product_list:\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23485c55",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b668b18",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47219cf4",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73dbffb1",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "loaded_model = load_model(\"modelprod_current_accounts.h5\")\n",
    "print(f\"Loaded model from {model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07787cb1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-02T16:38:21.028918Z",
     "iopub.status.busy": "2024-05-02T16:38:21.028207Z",
     "iopub.status.idle": "2024-05-02T16:38:21.034160Z",
     "shell.execute_reply": "2024-05-02T16:38:21.033138Z",
     "shell.execute_reply.started": "2024-05-02T16:38:21.028884Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "product_list = [\n",
    "#     'prod_guarantees',\n",
    "#     'prod_current_accounts',\n",
    "#     'prod_derivative_account',\n",
    "#     'prod_payroll_account',\n",
    "#     'prod_junior_account',\n",
    "#     'prod_mas_particular_account',\n",
    "#     'prod_particular_account',\n",
    "#     'prod_particular_plus_account',\n",
    "#     'prod_short_term_deposits',\n",
    "#     'prod_medium_term_deposits',\n",
    "#     'prod_long_term_deposits',\n",
    "#     'prod_e_account',\n",
    "#     'prod_funds',\n",
    "#     'prod_mortgage',\n",
    "#     'prod_pensions1',\n",
    "#     'prod_loans',\n",
    "#     'prod_taxes',\n",
    "#     'prod_credit_card',\n",
    "#     'prod_securities',\n",
    "#     'prod_home_account',\n",
    "#     'prod_payroll',\n",
    "#     'prod_pensions2',\n",
    "    'prod_direct_debit'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa315f47",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "# Initialize a counter to keep track of model iterations\n",
    "model_counter = 1\n",
    "\n",
    "for col in product_list:\n",
    "    print(col)\n",
    "    if train[col].nunique() == 2:\n",
    "        y = y_test[col]\n",
    "        model.fit(X_train, y_train[col], epochs=2, batch_size=32, validation_split=0.2)\n",
    "        xgb_probabilities = model.predict(X_test)\n",
    "        pred[col] = xgb_probabilities\n",
    "       # Save the model to the output directory\n",
    "        model.save(f\"/kaggle/working/model{col}.h5\")\n",
    "        print(f\"Saved model as model{col}.h5\")\n",
    "        model_counter += 1\n",
    "    else:\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e145eb80",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-02T18:46:14.571272Z",
     "iopub.status.busy": "2024-05-02T18:46:14.570877Z",
     "iopub.status.idle": "2024-05-02T18:46:14.796545Z",
     "shell.execute_reply": "2024-05-02T18:46:14.795102Z",
     "shell.execute_reply.started": "2024-05-02T18:46:14.571244Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "# Replace \"/kaggle/working/modelprod_payroll.h5\" with the actual path to your saved model\n",
    "model_path = \"/kaggle/working/modelprod_payroll.h5\"\n",
    "\n",
    "loaded_model = load_model(model_path)\n",
    "print(f\"Loaded model from {model_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02afc418",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Example dictionary\n",
    "datad = {\n",
    "    'prod_guarantees': np.array([[1.4795244e-05],\n",
    "                                 [1.5492973e-05],\n",
    "                                 [2.2213326e-05],\n",
    "                                 [2.3030307e-05],\n",
    "                                 [1.4767839e-05],\n",
    "                                 [1.4860431e-05]])\n",
    "}\n",
    "\n",
    "# Remove outer array brackets and flatten the arrays\n",
    "for key in datad:\n",
    "    datad[key] = datad[key].flatten()\n",
    "\n",
    "# Print the modified dictionary\n",
    "print(datad)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "887f2de2",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for j in pred:\n",
    "    print(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "450aa8b7",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for key in pred:\n",
    "    pred[key] = pred[key].flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09539230",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "pred "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0921a2f",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "pred_df = pd.DataFrame(pred)\n",
    "\n",
    "data_subset = X_test\n",
    "\n",
    "concatenated_data = pd.concat([data_subset.reset_index(drop=True), pred_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f06f4098",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "pred_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81068757",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def gbdt_product_recommender(df, row_number, top_n):\n",
    "    \n",
    "    prod_list = df.iloc[row_number, -len(pred_df.columns):].reset_index()\n",
    "    prod_list.columns = ['product', 'pred_score']\n",
    "    prod_list = prod_list.sort_values(by='pred_score', ascending=False)\n",
    "    \n",
    "    prod_list = prod_list[prod_list['pred_score'] >= 0.000001]\n",
    "    recommend_list = prod_list.head(top_n)\n",
    "    \n",
    "    if recommend_list.empty:\n",
    "        print(\"Based on the customer's info, there is no bank product recommended for now\")\n",
    "    \n",
    "    return recommend_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50442589",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "gbdt_product_recommender(concatenated_data ,11,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84b68dd3",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(pred.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfb21a2a",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "first_values_list = []\n",
    "\n",
    "# Iterate over the values (prediction arrays) in the pred dictionary\n",
    "for predictions in pred.values():\n",
    "    first_values_list.append(predictions[0])\n",
    "first_values_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "168c8390",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i in first_values_list:\n",
    "    print(len(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69fb8447",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "# Thompson Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0251337a",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "myprob= xgb_probabilities[0]\n",
    "list1=[]\n",
    "for i in myprob:\n",
    "    list1.append(i)\n",
    "list1    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e25523",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Thompson Sampling function\n",
    "def thompson_sampling(prod_prob, num_samples):\n",
    "    rewards = np.zeros(len(prod_prob))  # Initialize rewards for each product\n",
    "    selections = np.zeros(len(prod_prob))  # Initialize counts of selections for each product\n",
    "    \n",
    "    # Iterate for num_samples\n",
    "    for _ in range(num_samples):\n",
    "        # Sample from beta distribution for each product\n",
    "        sampled_values = [np.random.beta(rewards[i] + 1, selections[i] - rewards[i] + 1) for i in range(len(prod_prob))]\n",
    "        \n",
    "        # Select the product with the highest sampled value\n",
    "        selected_product = np.argmax(sampled_values)\n",
    "        \n",
    "        # Update rewards and selections\n",
    "        reward = np.random.choice([0, 1], p=[1 - prod_prob[selected_product], prod_prob[selected_product]])\n",
    "        rewards[selected_product] += reward\n",
    "        selections[selected_product] += 1\n",
    "    \n",
    "    return rewards, selections\n",
    "\n",
    "# Example usage\n",
    "prod_prob = list1  # Example probabilities for products\n",
    "num_samples = 10000  # Number of iterations for Thompson Sampling\n",
    "\n",
    "# Run Thompson Sampling\n",
    "rewards, selections = thompson_sampling(prod_prob, num_samples)\n",
    "\n",
    "# Print results\n",
    "print(\"Estimated rewards for each product:\", rewards)\n",
    "print(\"Number of selections for each product:\", selections)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a2334ff",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "# Epsilon Greedy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0689795b",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def epsilon_greedy(prod_prob, num_samples, epsilon):\n",
    "    rewards = np.zeros(len(prod_prob))  # Initialize rewards for each product\n",
    "    selections = np.zeros(len(prod_prob))  # Initialize counts of selections for each product\n",
    "    \n",
    "    # Iterate for num_samples\n",
    "    for _ in range(num_samples):\n",
    "        # Epsilon-greedy action selection\n",
    "        if np.random.rand() < epsilon:\n",
    "            # Randomly select a product\n",
    "            selected_product = np.random.choice(len(prod_prob))\n",
    "        else:\n",
    "            # Select the product with the highest estimated probability\n",
    "            selected_product = np.argmax(rewards / (selections + 1))\n",
    "        \n",
    "        # Update rewards and selections\n",
    "        reward = np.random.choice([0, 1], p=[1 - prod_prob[selected_product], prod_prob[selected_product]])\n",
    "        rewards[selected_product] += reward\n",
    "        selections[selected_product] += 1\n",
    "    \n",
    "    return rewards, selections\n",
    "\n",
    "# Example usage\n",
    "epsilon = 0.1  # Epsilon value for epsilon-greedy\n",
    "num_samples = 10000  # Number of iterations\n",
    "\n",
    "# Run epsilon-greedy\n",
    "rewards_eg, selections_eg = epsilon_greedy(list1, num_samples, epsilon)\n",
    "\n",
    "# Print results\n",
    "print(\"Epsilon-Greedy: Estimated rewards for each product:\", rewards_eg)\n",
    "print(\"Epsilon-Greedy: Number of selections for each product:\", selections_eg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d197de58",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Generate x-axis values for the number of products\n",
    "x_values = np.arange(len(list1))\n",
    "\n",
    "# Plotting the oracle probabilities\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(x_values, list1, color='blue', alpha=0.5, label='Oracle Probabilities')\n",
    "\n",
    "plt.xlabel('Product Index')\n",
    "plt.ylabel('Oracle Probability')\n",
    "plt.title('Oracle Probabilities')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f59cf598",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plotting the rewards obtained\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(x_values, rewards_eg, color='red', alpha=0.5, label='Estimated Rewards')\n",
    "\n",
    "plt.xlabel('Product Index')\n",
    "plt.ylabel('Estimated Reward')\n",
    "plt.title('Estimated Rewards')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b003d4b",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a list of tuples containing product name, reward, and selections\n",
    "product_rewards_selections = [(product_list[i], rewards_eg[i], selections_eg[i]) for i in range(len(product_list))]\n",
    "\n",
    "# Sort the list based on rewards in descending order\n",
    "product_rewards_selections_sorted = sorted(product_rewards_selections, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Print the sorted list\n",
    "for product, reward, selections in product_rewards_selections_sorted:\n",
    "    print(f\"{product}: Reward={reward}, Selections={int(selections)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a4fac05",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "# UCB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ea4d0a",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def ucb(prod_prob, num_samples):\n",
    "    rewards = np.zeros(len(prod_prob))  # Initialize rewards for each product\n",
    "    selections = np.zeros(len(prod_prob))  # Initialize counts of selections for each product\n",
    "    \n",
    "    # Iterate for num_samples\n",
    "    for t in range(1, num_samples + 1):\n",
    "        # UCB action selection\n",
    "        ucb_values = rewards / selections + np.sqrt(2 * np.log(t) / selections)\n",
    "        selected_product = np.argmax(ucb_values)\n",
    "        \n",
    "        # Update rewards and selections\n",
    "        reward = np.random.choice([0, 1], p=[1 - prod_prob[selected_product], prod_prob[selected_product]])\n",
    "        rewards[selected_product] += reward\n",
    "        selections[selected_product] += 1\n",
    "    \n",
    "    return rewards, selections\n",
    "\n",
    "# Example usage\n",
    "num_samples = 10000  # Number of iterations\n",
    "\n",
    "# Run UCB\n",
    "rewards_ucb, selections_ucb = ucb(list1, num_samples)\n",
    "\n",
    "# Print results\n",
    "print(\"UCB: Estimated rewards for each product:\", rewards_ucb)\n",
    "print(\"UCB: Number of selections for each product:\", selections_ucb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a8c80b",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Generate x-axis values for the number of products\n",
    "x_values = np.arange(len(list1))\n",
    "\n",
    "# Plotting the rewards obtained by UCB\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(x_values, rewards_ucb, color='blue', alpha=0.5, label='Estimated Rewards (UCB)')\n",
    "\n",
    "# Adding labels and title to the plot\n",
    "plt.xlabel('Product Index')\n",
    "plt.ylabel('Estimated Reward')\n",
    "plt.title('Estimated Rewards (UCB)')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b43350e0",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a list of tuples containing product name, reward, and selections\n",
    "ucb_rewards_selections = [(product_list[i], rewards_ucb[i], selections_ucb[i]) for i in range(len(product_list))]\n",
    "\n",
    "# Sort the list based on rewards in descending order\n",
    "ucb_rewards_selections_sorted = sorted(ucb_rewards_selections, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Print the sorted list\n",
    "for product, reward, selections in ucb_rewards_selections_sorted:\n",
    "    print(f\"{product}: Reward={reward}, Selections={int(selections)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7bea22a",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 4836455,
     "sourceId": 8171814,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30698,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 96.641919,
   "end_time": "2024-05-02T18:50:21.706410",
   "environment_variables": {},
   "exception": true,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-05-02T18:48:45.064491",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
